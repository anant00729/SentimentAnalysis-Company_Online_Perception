{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Data Notebook\n",
    "\n",
    "This notebook preps the scraped twitter data for sentiment classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from clean_tweets import clean_tweet, tweet_filtering\n",
    "import string\n",
    "import dataframe_image as dfi\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning (Twitter API)\n",
    "\n",
    "In this section we clean the data scraped from  the twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Data Summary\n",
    "\n",
    "In this section, we produce an initial data summary for a sanity check.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_datetime(dt_str: str):\n",
    "    \"\"\"\n",
    "    This function parses the datetime of a string into a python datetime\n",
    "    dt_str: Raw datetime string\n",
    "    returns: Datetime as a datetime type variable\n",
    "    \"\"\"\n",
    "    return datetime.strptime(dt_str,'%a %b %d %H:%M:%S +0000 %Y').date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining list of target companies\n",
    "screen_names = ['AdaniOnline', 'Microsoft', 'FTX_Official', 'Meta', 'AirCanada', 'fia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initializing list to hold results\n",
    "data_all = []\n",
    "\n",
    "# Iterating through each company\n",
    "for screen_name in screen_names:\n",
    "    data = {}\n",
    "    \n",
    "    # Reading in the tweets\n",
    "    df = pd.read_csv(f\"data/{screen_name}_tweets.csv\", index_col=0)\n",
    "    \n",
    "    # Parsing the date\n",
    "    df['date'] = df['date'].apply(lambda date: parse_datetime(date))\n",
    "    df['date'] = pd.to_datetime(df['date'] )\n",
    "    \n",
    "    # Creating summary data\n",
    "    data['Twitter Handle'] = screen_name\n",
    "    data['Start Date'] = df['date'].min()\n",
    "    data['End Date'] = df['date'].max()\n",
    "    data['Number of Tweets'] = len(df)\n",
    "    \n",
    "    data_all.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Twitter Handle</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "      <th>Number of Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaniOnline</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>2023-03-05</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>4775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FTX_Official</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meta</td>\n",
       "      <td>2023-03-05</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AirCanada</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2023-03-16</td>\n",
       "      <td>864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fia</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2023-03-16</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Twitter Handle Start Date   End Date  Number of Tweets\n",
       "0    AdaniOnline 2023-03-06 2023-03-15               255\n",
       "1      Microsoft 2023-03-05 2023-03-15              4775\n",
       "2   FTX_Official 2023-03-06 2023-03-15                51\n",
       "3           Meta 2023-03-05 2023-03-15               831\n",
       "4      AirCanada 2023-03-06 2023-03-16               864\n",
       "5            fia 2023-03-06 2023-03-16               602"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_summary_api = pd.DataFrame(data_all)\n",
    "data_summary_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Tweets:  7378\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Number of Tweets: \", data_summary_api[\"Number of Tweets\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cleaning Data\n",
    "\n",
    "In this section we actually clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_all = []\n",
    "api_df = []\n",
    "for screen_name in screen_names:\n",
    "    data = {}\n",
    "    \n",
    "    # Reading in the tweets\n",
    "    df = pd.read_csv(f\"data/{screen_name}_tweets.csv\", index_col=0)\n",
    "    \n",
    "    # Removing tweets with non-ascii characters (i.e. emogies)\n",
    "    df['filter'] = df['text'].apply(lambda text: tweet_filtering(text))\n",
    "    df = df[df['filter'] == False]\n",
    "    \n",
    "    # Cleaning the tweets\n",
    "    df['text'] = df['text'].apply(lambda text: clean_tweet(text))\n",
    "    \n",
    "    # Removing empty tweets\n",
    "    df = df[df['text'] != \"\"]\n",
    "    \n",
    "    # Parsing the date\n",
    "    df['date'] = df['date'].apply(lambda date: parse_datetime(date))\n",
    "    df['date'] = pd.to_datetime(df['date'] )\n",
    "    \n",
    "    df[\"twitter_handle\"] = screen_name\n",
    "    \n",
    "    api_df.append(df)\n",
    "\n",
    "    # Creating summary data\n",
    "    data['Twitter Handle'] = screen_name\n",
    "    data['Start Date'] = df['date'].min()\n",
    "    data['End Date'] = df['date'].max()\n",
    "    data['Number of Tweets'] = len(df)\n",
    "    \n",
    "    data_all.append(data)\n",
    "    \n",
    "    df.to_csv(f\"data/{screen_name}_tweets_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_df = pd.concat(api_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Twitter Handle</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "      <th>Number of Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaniOnline</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>2023-03-05</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>2964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FTX_Official</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meta</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AirCanada</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2023-03-16</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fia</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2023-03-16</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Twitter Handle Start Date   End Date  Number of Tweets\n",
       "0    AdaniOnline 2023-03-06 2023-03-15                34\n",
       "1      Microsoft 2023-03-05 2023-03-15              2964\n",
       "2   FTX_Official 2023-03-06 2023-03-15                10\n",
       "3           Meta 2023-03-06 2023-03-15               205\n",
       "4      AirCanada 2023-03-06 2023-03-16               259\n",
       "5            fia 2023-03-06 2023-03-16               191"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_summary_api_cleaned = pd.DataFrame(data_all)\n",
    "data_summary_api_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Tweets:  3663\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Number of Tweets: \", data_summary_api_cleaned[\"Number of Tweets\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Cleaning (Selenium)\n",
    "\n",
    "In this section we clean the data scraped from Twitter using Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Initial Data Summary\n",
    "\n",
    "In this section, we produce an initial data summary for a sanity check.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selenium_scraped = pd.read_csv(\n",
    "    \"data/tweet_with_replies_all.csv\",\n",
    "   header=None\n",
    ")\n",
    "\n",
    "selenium_scraped.columns = columns=[\"twitter_handle\", \"text\", \"parent_id\", \"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selenium_scraped = selenium_scraped[selenium_scraped[\"twitter_handle\"].isin(['AdaniOnline', 'Microsoft', 'FTX_Official', 'Meta', 'AirCanada', 'fia'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "twitter_handles = selenium_scraped[\"twitter_handle\"].unique()\n",
    "\n",
    "selenium_scraped['date'] = selenium_scraped['date'].apply(lambda date: parse_datetime(date))\n",
    "\n",
    "data_all = []\n",
    "for twitter_handle in twitter_handles:\n",
    "    \n",
    "    data = {}\n",
    "    \n",
    "    df = selenium_scraped[selenium_scraped[\"twitter_handle\"] == twitter_handle]\n",
    "    \n",
    "    \n",
    "    # Creating summary data\n",
    "    data['Twitter Handle'] = twitter_handle\n",
    "    data['Start Date'] = df['date'].min()\n",
    "    data['End Date'] = df['date'].max()\n",
    "    data['Number of Tweets'] = len(df)\n",
    "    \n",
    "    data_all.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Twitter Handle</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "      <th>Number of Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>2022-10-17</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AirCanada</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>1392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meta</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>1265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fia</td>\n",
       "      <td>2021-08-15</td>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>4554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Twitter Handle  Start Date    End Date  Number of Tweets\n",
       "0      Microsoft  2022-10-17  2023-03-15              1252\n",
       "1      AirCanada  2022-09-27  2023-03-13              1392\n",
       "2           Meta  2020-01-14  2023-02-27              1265\n",
       "3            fia  2021-08-15  2023-03-14              4554"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selenium_summary = pd.DataFrame(data_all)\n",
    "selenium_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Tweets:  8463\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Number of Tweets: \", selenium_summary[\"Number of Tweets\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cleaning Data\n",
    "\n",
    "In this section we actually clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removing empty tweets\n",
    "selenium_scraped = selenium_scraped[selenium_scraped['text'].isna() == False]\n",
    "selenium_scraped = selenium_scraped[selenium_scraped['text'] != \"\"]\n",
    "\n",
    "# Removing tweets with non-ascii characters (i.e. emogies)\n",
    "selenium_scraped['filter'] = selenium_scraped['text'].apply(lambda text: tweet_filtering(text))\n",
    "\n",
    "selenium_scraped = selenium_scraped[selenium_scraped['filter'] == False]\n",
    "\n",
    "# Cleaning the tweets\n",
    "selenium_scraped['text'] = selenium_scraped['text'].apply(lambda text: clean_tweet(text))\n",
    "\n",
    "# Removing empty tweets\n",
    "selenium_scraped = selenium_scraped[selenium_scraped['text'] != \"\"]\n",
    "\n",
    "# Parsing the data\n",
    "# selenium_scraped['date'] = selenium_scraped['date'].apply(lambda date: parse_datetime(date))\n",
    "selenium_scraped['date'] = pd.to_datetime(selenium_scraped['date'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selenium_scraped.to_csv(\"results/tweet_with_replies_all_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "twitter_handles = selenium_scraped[\"twitter_handle\"].unique()\n",
    "\n",
    "data_all = []\n",
    "for twitter_handle in twitter_handles:\n",
    "    \n",
    "    data = {}\n",
    "    \n",
    "    df = selenium_scraped[selenium_scraped[\"twitter_handle\"] == twitter_handle]\n",
    "    \n",
    "    # Creating summary data\n",
    "    data['Twitter Handle'] = twitter_handle\n",
    "    data['Start Date'] = df['date'].min()\n",
    "    data['End Date'] = df['date'].max()\n",
    "    data['Number of Tweets'] = len(df)\n",
    "    \n",
    "    data_all.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Twitter Handle</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "      <th>Number of Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>2022-10-17</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>1058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AirCanada</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meta</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fia</td>\n",
       "      <td>2021-08-15</td>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>3599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Twitter Handle Start Date   End Date  Number of Tweets\n",
       "0      Microsoft 2022-10-17 2023-03-15              1058\n",
       "1      AirCanada 2022-09-27 2023-03-13               983\n",
       "2           Meta 2020-01-14 2023-02-27               906\n",
       "3            fia 2021-08-15 2023-03-14              3599"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selenium_summary_cleaned = pd.DataFrame(data_all)\n",
    "selenium_summary_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Tweets:  6546\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Number of Tweets: \", selenium_summary_cleaned[\"Number of Tweets\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initial Comparison (i.e. Uncleaned)\n",
    "\n",
    "In this section, we produce a table to compare the two datasets (uncleaned versions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merging the two datasets together\n",
    "data_merged = pd.merge(left=data_summary_api, right=selenium_summary, how='outer', on=\"Twitter Handle\", suffixes=(' API', ' Selenium'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting the index\n",
    "data_merged.set_index(\"Twitter Handle\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_merged[\"Start Date API\"] = data_merged[\"Start Date API\"].astype(str)\n",
    "data_merged[\"End Date API\"] = data_merged[\"Start Date API\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged['Number of Tweets API'] = data_merged['Number of Tweets API'].fillna(0).astype(int)\n",
    "data_merged['Number of Tweets Selenium'] = data_merged['Number of Tweets Selenium'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating multi-indexed columns\n",
    "columns = list(data_summary_api.columns[1:]) + list(data_summary_api.columns[1:])\n",
    "\n",
    "types = [\"API\" for i in range(0,3)] + [\"Selenium\" for i in range(0,3)]\n",
    "\n",
    "multi_index_columns = list(zip(types, columns))\n",
    "\n",
    "data_merged.columns = pd.MultiIndex.from_tuples(multi_index_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">API</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Selenium</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "      <th>Number of Tweets</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "      <th>Number of Tweets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Twitter Handle</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaniOnline</th>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Microsoft</th>\n",
       "      <td>2023-03-05</td>\n",
       "      <td>2023-03-05</td>\n",
       "      <td>4775</td>\n",
       "      <td>2022-10-17</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTX_Official</th>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta</th>\n",
       "      <td>2023-03-05</td>\n",
       "      <td>2023-03-05</td>\n",
       "      <td>831</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>1265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AirCanada</th>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>864</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>1392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fia</th>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>602</td>\n",
       "      <td>2021-08-15</td>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>4554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       API                                 Selenium  \\\n",
       "                Start Date    End Date Number of Tweets  Start Date   \n",
       "Twitter Handle                                                        \n",
       "AdaniOnline     2023-03-06  2023-03-06              255         NaN   \n",
       "Microsoft       2023-03-05  2023-03-05             4775  2022-10-17   \n",
       "FTX_Official    2023-03-06  2023-03-06               51         NaN   \n",
       "Meta            2023-03-05  2023-03-05              831  2020-01-14   \n",
       "AirCanada       2023-03-06  2023-03-06              864  2022-09-27   \n",
       "fia             2023-03-06  2023-03-06              602  2021-08-15   \n",
       "\n",
       "                                             \n",
       "                  End Date Number of Tweets  \n",
       "Twitter Handle                               \n",
       "AdaniOnline            NaN                0  \n",
       "Microsoft       2023-03-15             1252  \n",
       "FTX_Official           NaN                0  \n",
       "Meta            2023-02-27             1265  \n",
       "AirCanada       2023-03-13             1392  \n",
       "fia             2023-03-14             4554  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replacing some empty values\n",
    "data_merged = data_merged.fillna(\"\")\n",
    "data_merged = data_merged.replace(\"NaT\", \"\")\n",
    "data_merged = data_merged.replace(0, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0330/094254.146198:WARNING:bluez_dbus_manager.cc(247)] Floss manager not present, cannot set Floss enable/disable.\n",
      "[0330/094254.148220:WARNING:sandbox_linux.cc(393)] InitializeSandbox() called with multiple threads in process gpu-process.\n",
      "[0330/094254.255960:INFO:headless_shell.cc(107)] 50413 bytes written to file /tmp/tmp1bz9cva3/temp.png\n"
     ]
    }
   ],
   "source": [
    "# Setting styles and writing to disk\n",
    "data_merged = data_merged.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\n",
    "data_merged.set_properties(**{'text-align': 'center'})\n",
    "dfi.export(data_merged, 'results/twitter_data_merged.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Merging\n",
    "\n",
    "In this section we merge the two data sets into a single set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def similar(a: str, b: str):\n",
    "    # CITATION: https://stackoverflow.com/questions/17388213/find-the-similarity-metric-between-two-strings\n",
    "    \"\"\"\n",
    "    This function compares two strings to determine their similarity\n",
    "    a: string 1\n",
    "    b: string 2\n",
    "    return: Similarity measure between 0 and 1\n",
    "    \"\"\"\n",
    "    return SequenceMatcher(lambda x: x == \" \", a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dropping unnessecary column\n",
    "selenium_scraped = selenium_scraped.drop(['parent_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dropping unnessecary column\n",
    "api_df = api_df.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We merge both datasets\n",
    "df_merged = pd.concat([selenium_scraped, api_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "df_merged = df_merged.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitter_handle</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>filter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>hello</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>don't you think that chatgpt 3 is biased</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>takes us back</td>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>my xbox since 2003</td>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>still runs like a charm</td>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10204</th>\n",
       "      <td>fia</td>\n",
       "      <td>rt</td>\n",
       "      <td>2023-03-07</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10205</th>\n",
       "      <td>fia</td>\n",
       "      <td>rt</td>\n",
       "      <td>2023-03-07</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10206</th>\n",
       "      <td>fia</td>\n",
       "      <td>rt  something more important</td>\n",
       "      <td>2023-03-07</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10207</th>\n",
       "      <td>fia</td>\n",
       "      <td>rt</td>\n",
       "      <td>2023-03-07</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10208</th>\n",
       "      <td>fia</td>\n",
       "      <td>rt  its a shame that</td>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10209 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      twitter_handle                                      text       date  \\\n",
       "0          Microsoft                                     hello 2023-03-15   \n",
       "1          Microsoft  don't you think that chatgpt 3 is biased 2023-03-15   \n",
       "2          Microsoft                             takes us back 2023-03-14   \n",
       "3          Microsoft                        my xbox since 2003 2023-03-14   \n",
       "4          Microsoft                   still runs like a charm 2023-03-14   \n",
       "...              ...                                       ...        ...   \n",
       "10204            fia                                       rt  2023-03-07   \n",
       "10205            fia                                       rt  2023-03-07   \n",
       "10206            fia              rt  something more important 2023-03-07   \n",
       "10207            fia                                       rt  2023-03-07   \n",
       "10208            fia                      rt  its a shame that 2023-03-06   \n",
       "\n",
       "       filter  \n",
       "0       False  \n",
       "1       False  \n",
       "2       False  \n",
       "3       False  \n",
       "4       False  \n",
       "...       ...  \n",
       "10204   False  \n",
       "10205   False  \n",
       "10206   False  \n",
       "10207   False  \n",
       "10208   False  \n",
       "\n",
       "[10209 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering: Microsoft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69196/3014575831.py:22: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df_cross_joined = pd.merge(df, df, on ='key', suffixes=('_L', '_R')).drop(\"key\", 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering: AirCanada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69196/3014575831.py:22: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df_cross_joined = pd.merge(df, df, on ='key', suffixes=('_L', '_R')).drop(\"key\", 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering: Meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69196/3014575831.py:22: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df_cross_joined = pd.merge(df, df, on ='key', suffixes=('_L', '_R')).drop(\"key\", 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering: fia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69196/3014575831.py:22: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df_cross_joined = pd.merge(df, df, on ='key', suffixes=('_L', '_R')).drop(\"key\", 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering: AdaniOnline\n",
      "Filtering: FTX_Official\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69196/3014575831.py:22: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df_cross_joined = pd.merge(df, df, on ='key', suffixes=('_L', '_R')).drop(\"key\", 1)\n",
      "/tmp/ipykernel_69196/3014575831.py:22: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df_cross_joined = pd.merge(df, df, on ='key', suffixes=('_L', '_R')).drop(\"key\", 1)\n"
     ]
    }
   ],
   "source": [
    "# Getting list of twitter handles\n",
    "twitter_handles = df_merged[\"twitter_handle\"].unique()\n",
    "\n",
    "# Creating list to hold unique tweets for each handle\n",
    "df_duplicate_free = []\n",
    "\n",
    "# Iterating through each handle\n",
    "for twitter_handle in twitter_handles:\n",
    "    print(\"Filtering:\", twitter_handle)\n",
    "\n",
    "    # Filtering to specific twitter handle\n",
    "    df = df_merged[df_merged[\"twitter_handle\"] == twitter_handle]\n",
    "\n",
    "    # We reset the index since so we can use it to filter out comparisons against themselves\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # CITATION: https://www.geeksforgeeks.org/python-program-to-perform-cross-join-in-pandas/\n",
    "    # Creating dummy key\n",
    "    df['key'] = 1\n",
    "\n",
    "    # Performing cross join\n",
    "    df_cross_joined = pd.merge(df, df, on ='key', suffixes=('_L', '_R')).drop(\"key\", 1)\n",
    "\n",
    "    # Filtering out tweets that aren't from the same time\n",
    "    df_cross_joined = df_cross_joined[df_cross_joined[\"date_L\"] == df_cross_joined[\"date_R\"]]\n",
    "\n",
    "    # Filtering out comparisons against themselves\n",
    "    df_cross_joined = df_cross_joined[df_cross_joined[\"index_L\"] != df_cross_joined[\"index_R\"]]\n",
    "\n",
    "    # If there are still potential duplicates\n",
    "    if len(df_cross_joined) > 0:\n",
    "        # Computing the similarity between each pair of tweets\n",
    "        df_cross_joined['similarity'] = df_cross_joined.apply(lambda row: similar(row[\"text_L\"], row[\"text_R\"]), axis=1)\n",
    "\n",
    "        # Filtering to the duplicates\n",
    "        duplicates = df_cross_joined[df_cross_joined['similarity'] > 0.9]\n",
    "\n",
    "        # Removing the duplicates\n",
    "        df[df['index'].isin(duplicates['index_R']) == False]\n",
    "\n",
    "    # Adding the duplicate free result\n",
    "    df_duplicate_free.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merging everything together\n",
    "df_duplicate_free = pd.concat(df_duplicate_free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Resetting the index\n",
    "df_duplicate_free = df_duplicate_free.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dropping unneeded columns\n",
    "df_duplicate_free = df_duplicate_free.drop([\"filter\", \"index\", \"key\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Writing to disk\n",
    "df_duplicate_free.to_csv(\"results/twitter_scraped_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merged Data Summary\n",
    "\n",
    "In this section we produce a final summary of the merged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reading in the above data since computing the cleaned data can take a while\n",
    "df_duplicate_free = pd.read_csv(\"results/twitter_scraped_cleaned.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting list of the twitter handles\n",
    "twitter_handles = df_duplicate_free[\"twitter_handle\"].unique()\n",
    "\n",
    "# Creating list to hold results\n",
    "data_all = []\n",
    "\n",
    "# Iterating through each hanlde\n",
    "for twitter_handle in twitter_handles:\n",
    "    \n",
    "    # Initializing dict to hold result\n",
    "    data = {}\n",
    "        \n",
    "    # Filtering to the handle\n",
    "    df = df_duplicate_free[df_duplicate_free[\"twitter_handle\"] == twitter_handle]\n",
    "    \n",
    "    \n",
    "    # Creating summary data\n",
    "    data['Twitter Handle'] = twitter_handle\n",
    "    data['Start Date'] = df['date'].min()\n",
    "    data['End Date'] = df['date'].max()\n",
    "    data['Number of Tweets'] = len(df)\n",
    "    \n",
    "    # Adding the summary\n",
    "    data_all.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converting to DF and some basic processing\n",
    "duplicate_removed_summary = pd.DataFrame(data_all)\n",
    "duplicate_removed_summary[\"Start Date\"] = duplicate_removed_summary[\"Start Date\"].astype(str)\n",
    "duplicate_removed_summary[\"End Date\"] = duplicate_removed_summary[\"End Date\"].astype(str)\n",
    "duplicate_removed_summary.set_index(\"Twitter Handle\", inplace=True)                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We don't want to include these handles\n",
    "duplicate_removed_summary = duplicate_removed_summary[duplicate_removed_summary.index.isin(['AdaniOnline', 'FTX_Official']) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adding sample tweets\n",
    "duplicate_removed_summary[\"Example\"] = [\n",
    "    df_duplicate_free.iloc[4,]['text'], \n",
    "    df_duplicate_free.iloc[4034,]['text'],\n",
    "    df_duplicate_free.iloc[5277,]['text'], \n",
    "    df_duplicate_free.iloc[6396,]['text']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0330/093525.659324:WARNING:bluez_dbus_manager.cc(247)] Floss manager not present, cannot set Floss enable/disable.\n",
      "[0330/093525.667176:WARNING:sandbox_linux.cc(393)] InitializeSandbox() called with multiple threads in process gpu-process.\n",
      "[0330/093525.777998:INFO:headless_shell.cc(107)] 48269 bytes written to file /tmp/tmpret280um/temp.png\n"
     ]
    }
   ],
   "source": [
    "# Performing styling and writing table to png\n",
    "duplicate_removed_summary = duplicate_removed_summary.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\n",
    "('max-width', '5')\n",
    "duplicate_removed_summary = duplicate_removed_summary.set_properties(subset=['Example'], **{'width': '200px'})\n",
    "duplicate_removed_summary = duplicate_removed_summary.set_properties(**{'text-align': 'center'})\n",
    "dfi.export(duplicate_removed_summary, 'results/twitter_cleaned.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
