{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "# Output.ipynb\n",
    "\n",
    "This notebook contains detailed instructions on how to reproduce the results of this project.  Note, for detailed instructions on the scripts that are running in the following cells, please see the README.md in the appropriate directory for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "In the following subsections, it is expected that the user has downloaded the neccessary data so that each python notebook or script in this project can be run.  The required prerequisites must section **must** be completed before proceeding further.  The optional prerequites are optional.  It will be noted below when it is required.  Note, when you execute `download_output.py` the outputs and results of each model are automatically downloaded.  This allows the user to execute **most** cells but not all (i.e. the user can skip running the actual models, but will need to download the models if they actually want to regenerate the results)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "working_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install all requirements to run everything in this project\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This script downloads and propagates the datafiles required to run each script\n",
    "%run download_output.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuring GPU for PyTorch and Tensorflow\n",
    "\n",
    "Using the included requirements.txt file, this will download PyTorch and TensorFlow for CPU **only**.  If the user would like to use a GPU, we refer the reader to [PyTorch installation page](https://pytorch.org/get-started/locally/) or the [Tensorflow installation page](https://www.tensorflow.org/install/pip) so that they can download the appropriate GPU version.  Note, for PyTorch in this project we used version 2.0.0 and for Tensorflow we used version 2.12.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This script downloads the final models used in this project.  Note, depending on your internet speed this could take quite a while!\n",
    "!python download_models.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generating Training Data\n",
    "\n",
    "The following cell allows the user to generate the training data used to train both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cleans the Sentiment140 dataset and outputs training_data_formulation/results/tweets.csv\n",
    "os.chdir(f\"{working_directory}/training_data_formulation\")\n",
    "!python clean_tweets.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cleans the NewsMTSC dataset and outputs training_data_formulation/results/news.csv\n",
    "os.chdir(f\"{working_directory}/training_data_formulation\")\n",
    "!python clean_news.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merges the training data and generates all the splits (i.e. train/test/validation etc_\n",
    "os.chdir(f\"{working_directory}/training_data_formulation\")\n",
    "!papermill data_formulation.ipynb /dev/null\n",
    "\n",
    "# We copy all the resulting data splits to where they are used elsewhere in the project\n",
    "os.chdir(f\"{working_directory}\")\n",
    "shutil.copy(\"training_data_formulation/results/test_4000.csv\", \"bert/data/test_4000.csv\")\n",
    "shutil.copy(\"training_data_formulation/results/train_4000.csv\", \"bert/data/train_4000.csv\")\n",
    "shutil.copy(\"training_data_formulation/results/val_4000.csv\", \"bert/data/val_4000.csv\")\n",
    "\n",
    "shutil.copy(\"training_data_formulation/results/val_4000_news.csv\", \"bert/data/val_4000_news.csv\")\n",
    "shutil.copy(\"training_data_formulation/results/train_4000_news.csv\", \"bert/data/train_4000_news.csv\")\n",
    "shutil.copy(\"training_data_formulation/results/test_4000_news.csv\", \"bert/data/test_4000_news.csv\")\n",
    "\n",
    "shutil.copy(\"training_data_formulation/results/val_4000_tweets.csv\", \"bert/data/val_4000_tweets.csv\")\n",
    "shutil.copy(\"training_data_formulation/results/train_4000_tweets.csv\", \"bert/data/train_4000_tweets.csv\")\n",
    "shutil.copy(\"training_data_formulation/results/test_4000_tweets.csv\", \"bert/data/test_4000_tweets.csv\")\n",
    "\n",
    "shutil.copy(\"training_data_formulation/results/test_4000.csv\", \"lstm/data/test_4000.csv\")\n",
    "shutil.copy(\"training_data_formulation/results/train_4000.csv\", \"lstm/data/train_4000.csv\")\n",
    "shutil.copy(\"training_data_formulation/results/val_4000.csv\", \"lstm/data/val_4000.csv\")\n",
    "\n",
    "shutil.copy(\"training_data_formulation/results/val_4000_news.csv\", \"lstm/data/val_4000_news.csv\")\n",
    "shutil.copy(\"training_data_formulation/results/train_4000_news.csv\", \"lstm/data/train_4000_news.csv\")\n",
    "shutil.copy(\"training_data_formulation/results/test_4000_news.csv\", \"lstm/data/test_4000_news.csv\")\n",
    "\n",
    "shutil.copy(\"training_data_formulation/results/val_4000_tweets.csv\", \"lstm/data/val_4000_tweets.csv\")\n",
    "shutil.copy(\"training_data_formulation/results/train_4000_tweets.csv\", \"lstm/data/train_4000_tweets.csv\")\n",
    "shutil.copy(\"training_data_formulation/results/test_4000_tweets.csv\", \"lstm/data/test_4000_tweets.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Summary statistics of NewsMTSC data used in training data\n",
    "os.chdir(f\"{working_directory}/training_data_formulation\")\n",
    "Image(filename='results/news_stats.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Summary statistics of Sentiment140 data used in training data\n",
    "os.chdir(f\"{working_directory}/training_data_formulation\")\n",
    "Image(filename='results/tweets_stats.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Summary statistics of merged data used in trainng/validation/test splits\n",
    "os.chdir(f\"{working_directory}/training_data_formulation\")\n",
    "Image(filename='results/split_stats.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generating Bert Model Results\n",
    "\n",
    "**Optional Prerequisites Required**\n",
    "\n",
    "The following cell executes the `test.ipynb` notebook that executes the bert models on the training, vaidation and test datasets and produces a PNG of the results that is used in the final report.  The resulting PNG is shown below.  Note, actually running this could take quite a while (~ 10 minutes on an RTX 3090).  If you do not have an NVIDIA GPU with **at least** 8GB of vram, do not try and execute this, it will either take too long or you will get an out of memory error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(f\"{working_directory}/bert\")\n",
    "!papermill test.ipynb /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(f\"{working_directory}/bert\")\n",
    "Image(filename='results/bert_results_table.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generating LSTM Model Results\n",
    "\n",
    "**Optional Prerequisites Required**\n",
    "\n",
    "The following cell executes the LSTM model on the scraped data from Twitter and the New York Times.  This produces lstm/results/twitter_lstm_results.csv and lstm/results/nyt_lstm_results.csv.  These files are then moved to the result_visualizations/data directory and are used to produce the vizualizations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(f\"{working_directory}/lstm\")\n",
    "!papermill test.ipynb /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(f\"{working_directory}/lstm\")\n",
    "Image(filename='results/lstm_results_table.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Results on Scraped Data\n",
    "\n",
    "The following cells execute several scripts that allow the user to reproduce the results of both models on the scraped data from the New York Times and Twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Results of the Bert Model\n",
    "\n",
    "**Optional Prerequisites Required**\n",
    "\n",
    "The following cell executes the BERT model on the scraped data from Twitter and the New York Times.  This produces `bert/results/twitter_bert_results.csv` and `bert/results/nyt_bert_results.csv`.  These files are then moved to the `result_visualizations/data` directory and are used to produce the vizualizations. Note, actually running this could take quite a while (~ 10 minutes on an RTX 3090).  If you do not have an NVIDIA GPU with **at least** 8GB of vram, do not try and execute this, it will either take too long or you will get an out of memory error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(f\"{working_directory}/bert\")\n",
    "!papermill real_data_testing.ipynb /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(f\"{working_directory}\")\n",
    "shutil.copy(\"bert/results/twitter_bert_results.csv\", \"result_visualizations/data/twitter_bert_results.csv\")\n",
    "shutil.copy(\"bert/results/nyt_bert_results.csv\", \"result_visualizations/data/nyt_bert_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generating Results of the LSTM Model\n",
    "\n",
    "**Optional Prerequisites Required**\n",
    "\n",
    "The following cell executes the LSTM model on the scraped data from Twitter and the New York Times. This produces lstm/results/twitter_lstm_results.csv and lstm/results/nyt_lstm_results.csv. These files are then moved to the result_visualizations/data directory and are used to produce the vizualizations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(f\"{working_directory}/lstm\")\n",
    "!papermill real_data_lstm_testing.ipynb /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(f\"{working_directory}\")\n",
    "shutil.copy(\"lstm/results/twitter_lstm_results.csv\", \"result_visualizations/data/twitter_lstm_results.csv\")\n",
    "shutil.copy(\"lstm/results/nyt_lstm_results.csv\", \"result_visualizations/data/nyt_lstm_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generating Vizualizations the Results\n",
    "The following cell generates the vizualizations of the results from the previous two sections.  The vizualizations are then shown in the subsequent cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(f\"{working_directory}/result_visualizations\")\n",
    "!papermill viz.ipynb /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Twitter Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initial summary of LSTM model results on twitter data\n",
    "os.chdir(f\"{working_directory}/result_visualizations\")\n",
    "Image(filename='results/lstm_initial_twitter_summary_result.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initial summary of BERT model results on twitter data\n",
    "os.chdir(f\"{working_directory}/result_visualizations\")\n",
    "Image(filename='results/bert_initial_twitter_summary_result.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Timeseries vizualization of both model results on twitter data\n",
    "os.chdir(f\"{working_directory}/result_visualizations\")\n",
    "Image(filename='results/timeseries_distribution_grid.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Distribution vizualization of both model results on twitter data\n",
    "os.chdir(f\"{working_directory}/result_visualizations\")\n",
    "Image(filename='results/distribution_grid.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### New York Time Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initial summary of LSTM model results on NYT data\n",
    "os.chdir(f\"{working_directory}/result_visualizations\")\n",
    "Image(filename='results/lstm_initial_nyt_summary_result.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initial summary of BERT model results on NYT data\n",
    "os.chdir(f\"{working_directory}/result_visualizations\")\n",
    "Image(filename='results/bert_initial_nyt_summary_result.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Timeseries vizualization of both model results on NYT data\n",
    "os.chdir(f\"{working_directory}/result_visualizations\")\n",
    "Image(filename='results/nyt_timeseries_distribution_grid.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Distribution vizualization of both model results on NYT data\n",
    "os.chdir(f\"{working_directory}/result_visualizations\")\n",
    "Image(filename='results/nyt_distribution_grid.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
