{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GTNcHIEUxKzp"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_data_path = 'data/train_4000.csv'\n",
    "test_data_path = 'data/test_4000.csv'\n",
    "val_data_path = 'data/val_4000.csv'\n",
    "\n",
    "first_n_words = 200\n",
    "\n",
    "# Read raw data\n",
    "df_train = pd.read_csv(train_data_path)\n",
    "df_test = pd.read_csv(test_data_path)\n",
    "df_val = pd.read_csv(val_data_path)\n",
    "\n",
    "df_train[['label']] = df_train[['label']].replace([\"negative\", \"positive\"],[0, 1])\n",
    "df_test[['label']] = df_test[['label']].replace([\"negative\", \"positive\"],[0, 1])\n",
    "df_val[['label']] = df_val[['label']].replace([\"negative\", \"positive\"],[0, 1])\n",
    "\n",
    "\n",
    "# Take particular columns\n",
    "train_sentences = df_train['sequence'].values\n",
    "test_sentences = df_test['sequence'].values\n",
    "val_sentences = df_val['sequence'].values\n",
    "train_labels = df_train['label'].values\n",
    "test_labels = df_test['label'].values\n",
    "val_labels = df_val['label'].values\n",
    "\n",
    "\n",
    "# Hyperparameters of the model\n",
    "vocab_size = 3000 # choose based on statistics\n",
    "oov_tok = ''\n",
    "embedding_dim = 100\n",
    "max_length = 100 # choose based on statistics, for example 100 to 200\n",
    "padding_type='post'\n",
    "trunc_type='post'\n",
    "\n",
    "# tokenize sentences\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# convert train dataset to sequence and pad sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "train_padded = pad_sequences(train_sequences, padding='post', maxlen=max_length)\n",
    "\n",
    "# convert Test dataset to sequence and pad sequences\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "test_padded = pad_sequences(test_sequences, padding='post', maxlen=max_length)\n",
    "\n",
    "# convert Val dataset to sequence and pad sequences\n",
    "val_sequences = tokenizer.texts_to_sequences(val_sentences)\n",
    "val_padded = pad_sequences(val_sequences, padding='post', maxlen=max_length)"
   ],
   "metadata": {
    "id": "E0rebAlZxUcW"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_padded"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0XQUiW0Gc0Rn",
    "outputId": "fe7093cd-3b63-440b-a735-9e36155532fb"
   },
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 473,   94,   54, ...,    0,    0,    0],\n       [   1, 2697,    2, ...,    0,    0,    0],\n       [   1,   38, 1965, ...,    0,    0,    0],\n       ...,\n       [  26,   67,   13, ...,    0,    0,    0],\n       [  54, 2023, 2156, ...,    0,    0,    0],\n       [   1,  107,   14, ...,    0,    0,    0]], dtype=int32)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_padded"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MoG6cjUwc3tm",
    "outputId": "7fa67440-65f9-471f-8157-0449669abdcc"
   },
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1424,    0,    0, ...,    0,    0,    0],\n       [   1,    1,  592, ...,    0,    0,    0],\n       [1080,    4,  568, ...,    0,    0,    0],\n       ...,\n       [   4,  610,    6, ...,    0,    0,    0],\n       [1267,   70,    2, ...,    0,    0,    0],\n       [ 329,  932,    2, ...,    0,    0,    0]], dtype=int32)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "val_padded"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y1sktwN7dgzd",
    "outputId": "fd6714cb-1d4d-46a3-80ef-e05ae2d9b595"
   },
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 151,   37, 2315, ...,    0,    0,    0],\n       [ 682,   98,    4, ...,    0,    0,    0],\n       [   1,   69,  109, ...,    0,    0,    0],\n       ...,\n       [  35,    1,   27, ...,    0,    0,    0],\n       [ 248,  315,  837, ...,    0,    0,    0],\n       [  37,   34,   59, ...,    0,    0,    0]], dtype=int32)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Model initialization\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(64)),\n",
    "    keras.layers.Dense(24, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# Model summary\n",
    "model.summary()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LIRcZuyi0VBA",
    "outputId": "7a057d00-3a1d-4785-f759-f83562226407"
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 100)          300000    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              84480     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 24)                3096      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 387,601\n",
      "Trainable params: 387,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Training\n",
    "num_epochs = 3\n",
    "history = model.fit(train_padded, train_labels, \n",
    "                    epochs=num_epochs, verbose=1, \n",
    "                    validation_split=0.1)\n",
    "model.save('checkpoints/lstm-base-uncased_4000_0_best.h5')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h6d6EWNS0XA4",
    "outputId": "488948bd-eb5c-4b16-c3a3-75d7c23f6764"
   },
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-07 13:16:59.844515: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 [==============================] - 8s 42ms/step - loss: 0.6539 - accuracy: 0.6056 - val_loss: 0.5938 - val_accuracy: 0.6732\n",
      "Epoch 2/3\n",
      "158/158 [==============================] - 6s 37ms/step - loss: 0.4689 - accuracy: 0.7881 - val_loss: 0.5312 - val_accuracy: 0.7036\n",
      "Epoch 3/3\n",
      "158/158 [==============================] - 6s 37ms/step - loss: 0.3482 - accuracy: 0.8571 - val_loss: 0.5981 - val_accuracy: 0.7125\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Checking reconstruct the model identically.\n",
    "model_check = keras.models.load_model(\"checkpoints/lstm-base-uncased_4000_0_best.h5\")\n",
    "\n",
    "prediction = model_check.predict(test_padded)\n",
    "# Get labels based on probability 1 if p>= 0.5 else 0\n",
    "\n",
    "pred_labels = []\n",
    "for i in prediction:\n",
    "    if i >= 0.5:\n",
    "        pred_labels.append(1)\n",
    "    else:\n",
    "        pred_labels.append(0)\n",
    "print(\"Accuracy of prediction on test set : \", accuracy_score(test_labels,pred_labels))\n",
    "print(\"F1 Score of prediction on test set : \", f1_score(test_labels,pred_labels))\n",
    "print(\"Precision of prediction on val set : \", precision_score(test_labels,pred_labels))\n",
    "print(\"Recall of prediction on val set : \", recall_score(test_labels,pred_labels))\n",
    "\n",
    "df_test['predicted'] = pred_labels"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m1cK2Fbk0cEy",
    "outputId": "65e22893-55df-48e4-a79b-76bf42bb3711"
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 1s 10ms/step\n",
      "Accuracy of prediction on test set :  0.704375\n",
      "F1 Score of prediction on test set :  0.6451612903225806\n",
      "Precision of prediction on val set :  0.7142857142857143\n",
      "Recall of prediction on val set :  0.5882352941176471\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "prediction = model_check.predict(val_padded)\n",
    "# Get labels based on probability 1 if p>= 0.5 else 0\n",
    "\n",
    "pred_labels = []\n",
    "for i in prediction:\n",
    "    if i >= 0.5:\n",
    "        pred_labels.append(1)\n",
    "    else:\n",
    "        pred_labels.append(0)\n",
    "print(\"Accuracy of prediction on val set : \", accuracy_score(val_labels,pred_labels))\n",
    "print(\"F1 Score of prediction on val set : \", f1_score(val_labels,pred_labels))\n",
    "print(\"Precision of prediction on val set : \", precision_score(val_labels,pred_labels))\n",
    "print(\"Recall of prediction on val set : \", recall_score(val_labels,pred_labels))\n",
    "\n",
    "\n",
    "\n",
    "df_val['predicted'] = pred_labels"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7SsQtxyBdp_O",
    "outputId": "7cab1195-7315-4cf4-9308-aa43ab91db10"
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 10ms/step\n",
      "Accuracy of prediction on val set :  0.6825\n",
      "F1 Score of prediction on val set :  0.6231454005934719\n",
      "Precision of prediction on val set :  0.7094594594594594\n",
      "Recall of prediction on val set :  0.5555555555555556\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "prediction = model_check.predict(val_padded)\n",
    "# Get labels based on probability 1 if p>= 0.5 else 0\n",
    "\n",
    "pred_labels = []\n",
    "for i in prediction:\n",
    "    if i >= 0.5:\n",
    "        pred_labels.append(1)\n",
    "    else:\n",
    "        pred_labels.append(0)\n",
    "print(\"Accuracy of prediction on val set : \", accuracy_score(val_labels,pred_labels))\n",
    "print(\"F1 Score of prediction on val set : \", f1_score(val_labels,pred_labels))\n",
    "print(\"Precision of prediction on val set : \", precision_score(val_labels,pred_labels))\n",
    "print(\"Recall of prediction on val set : \", recall_score(val_labels,pred_labels))\n",
    "\n",
    "df_val['predicted'] = pred_labels"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VohN7BeHehhN",
    "outputId": "423c97ec-3aa3-4a49-d3f7-afd6ea837d2d"
   },
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 10ms/step\n",
      "Accuracy of prediction on val set :  0.6825\n",
      "F1 Score of prediction on val set :  0.6231454005934719\n",
      "Precision of prediction on val set :  0.7094594594594594\n",
      "Recall of prediction on val set :  0.5555555555555556\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Check on some given sentences\n",
    "sentence = [\"The movie was very touching and heart whelming\", \n",
    "            \"I have never seen a terrible movie like this\", \n",
    "            \"it was a drastic and abad turn around\",\n",
    "            \"game was amazing\",\n",
    "            \"nice one\",\n",
    "            \"looks bad\"]\n",
    "# convert to a sequence\n",
    "sequences = tokenizer.texts_to_sequences(sentence)\n",
    "print('token', tokenizer)\n",
    "print(sequences)\n",
    "# pad the sequence\n",
    "padded = pad_sequences(sequences, padding='post', maxlen=max_length)\n",
    "# Get labels based on probability 1 if p>= 0.5 else 0\n",
    "prediction = model_check.predict(padded)\n",
    "pred_labels = []\n",
    "for i in prediction:\n",
    "    if i >= 0.5:\n",
    "        pred_labels.append(1)\n",
    "    else:\n",
    "        pred_labels.append(0)\n",
    "for i in range(len(sentence)):\n",
    "    print(sentence[i])\n",
    "    if pred_labels[i] == 1:\n",
    "        s = 'Positive'\n",
    "    else:\n",
    "        s = 'Negative'\n",
    "    print(\"Predicted sentiment : \",s)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5VAvFmE3684m",
    "outputId": "4b2c5f4f-6298-465f-e5bb-48b489864b46"
   },
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token <keras.preprocessing.text.Tokenizer object at 0x168c23c70>\n",
      "[[2, 722, 15, 125, 1, 5, 946, 1], [8, 23, 181, 546, 4, 2316, 722, 53, 31], [17, 15, 4, 1, 5, 1, 693, 319], [772, 15, 924], [255, 48], [444, 208]]\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "The movie was very touching and heart whelming\n",
      "Predicted sentiment :  Positive\n",
      "I have never seen a terrible movie like this\n",
      "Predicted sentiment :  Negative\n",
      "it was a drastic and abad turn around\n",
      "Predicted sentiment :  Positive\n",
      "game was amazing\n",
      "Predicted sentiment :  Positive\n",
      "nice one\n",
      "Predicted sentiment :  Positive\n",
      "looks bad\n",
      "Predicted sentiment :  Negative\n"
     ]
    }
   ]
  }
 ]
}
